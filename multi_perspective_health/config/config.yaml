# config/config.yaml

data:
  train_path: "data/train.json"
  val_path: "data/valid.json"
  test_path: "data/test.json"
  tokenizer_name: "bert-base-uncased"
  max_seq_length: 512

model:
  encoder_model: "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract" 
  pretrained_model: "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract" 
  dropout: 0.1
  hidden_dim: 768
  use_crf: true
  num_tags: 13

training:
  batch_size: 8
  num_epochs: 3
  learning_rate: 3e-5
  weight_decay: 0.01
  warmup_steps: 100
  max_grad_norm: 1.0
  logging_steps: 50
  eval_steps: 200
  save_model: false
  save_path: "/kaggle/working/checkpoints/span_extractor_crf.pt"

label_map:
  O: 1
  B-INFORMATION: 2
  I-INFORMATION: 3
  B-SUGGESTION: 4
  I-SUGGESTION: 5
  B-CAUSE: 6
  I-CAUSE: 7
  B-EXPERIENCE: 8
  I-EXPERIENCE: 9
  B-QUESTION: 10
  I-QUESTION: 11

label_map_reverse:
  1: "O"
  2: "B-INFORMATION"
  3: "I-INFORMATION"
  4: "B-SUGGESTION"
  5: "I-SUGGESTION"
  6: "B-CAUSE"
  7: "I-CAUSE"
  8: "B-EXPERIENCE"
  9: "I-EXPERIENCE"
  10: "B-QUESTION"
  11: "I-QUESTION"


misc:
  seed: 42
  device: "cuda"
